{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio  \n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, AveragePooling2D, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import Model\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function is used for image interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(data,bigNum):\n",
    "    # only for dim is 3\n",
    "    if data.shape[-1] != 3:\n",
    "        return None\n",
    "    m = len(data)\n",
    "    data_interpolation = np.zeros((m,bigNum,bigNum,3))\n",
    "    for i in range(m):\n",
    "        data_interpolation[i] = resize(data[i], (bigNum, bigNum,3), mode='symmetric')\n",
    "    return data_interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = './data/'\n",
    "modelDir = './model'\n",
    "interpShape = 64\n",
    "augNum = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'baseline'\n",
    "path=dataDir + '/'+position+'/' + '/data_train'\n",
    "data=sio.loadmat(path)\n",
    "X_train = data['data_test']\n",
    "\n",
    "path=dataDir + '/'+position+'/' + '/label_train'\n",
    "data=sio.loadmat(path)\n",
    "label_train = data['label_test']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, label_train.reshape(-1), test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Image interpolation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = interpolation(X_train,interpShape)\n",
    "X_test_baseline = interpolation(X_test,interpShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform __data augmentation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_shift_range = 0.15\n",
    "height_shift_range = 0.15\n",
    "datagen = ImageDataGenerator(width_shift_range=width_shift_range, height_shift_range=height_shift_range)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "\n",
    "#generate images\n",
    "X_train_aug = []\n",
    "for i in range(augNum):\n",
    "    for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=len(X_train),shuffle = False):\n",
    "        # create a grid of 3x3 images\n",
    "        print('examples of augmented data')\n",
    "        for i in range(0, 9):\n",
    "            pyplot.subplot(330 + 1 + i)\n",
    "            pyplot.imshow(X_batch[i,:,:,0].reshape(interpShape, interpShape), cmap=pyplot.get_cmap('YlOrRd'))\n",
    "        # show the plot\n",
    "        pyplot.show()\n",
    "        break\n",
    "    X_train_aug.append(X_batch)\n",
    "    \n",
    "X_train_with_aug = X_train\n",
    "for i in range(augNum):\n",
    "    X_train_with_aug = np.vstack([X_train_with_aug, X_train_aug[i]])\n",
    "y_train_with_aug = np.zeros((len(y_train)*(augNum+1),))\n",
    "for i in range(len(y_train_with_aug)):\n",
    "    y_train_with_aug[i] = y_train[i%len(y_train)]\n",
    "    \n",
    "del X_train, X_train_aug\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "y_train_with_aug_onehot = keras.utils.to_categorical(y_train_with_aug, 6)\n",
    "y_test_onehot_baseline = keras.utils.to_categorical(y_test, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built __dilated convolutional neural networks__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNclf(input_shape):\n",
    "    input_img = Input(input_shape) # 50 50\n",
    "    x = Conv2D(8, (3, 3), activation='relu',dilation_rate=(3, 3), padding='same',name='e1',kernel_regularizer=regularizers.l2(0.001),\n",
    "              kernel_initializer = glorot_uniform(seed=0))(input_img)\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu',dilation_rate=(3, 3), padding='same',name='e2',kernel_regularizer=regularizers.l2(0.001),\n",
    "              kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu',dilation_rate=(3, 3), padding='same',name='e3',kernel_regularizer=regularizers.l2(0.001),\n",
    "              kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    \n",
    "    encoded = AveragePooling2D((2, 2), padding='same',name='e4')(x)\n",
    "    x = Flatten()(encoded)\n",
    "        \n",
    "    x = Dense(units=128, activation='relu',name = 'dense_layer1',kernel_regularizer=regularizers.l2(0.001),\n",
    "              kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    output_layer = Dense(units=6, activation='softmax',name = 'output_layer',kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    model = Model(inputs=input_img, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can directly use the pretrained model for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnclf = NNclf((interpShape,interpShape,3))\n",
    "nnclf.load_weights('./model/nnclf.h5',by_name = True)\n",
    "nnclf.compile(loss=categorical_crossentropy, optimizer=optimizers.Adam(lr=0.001), metrics=['acc'])\n",
    "print('electrode position: baseline')\n",
    "model_evaluate = []\n",
    "model_evaluate.append(nnclf.evaluate(X_test_baseline,y_test_onehot_baseline))\n",
    "print('model_evaluate',model_evaluate)\n",
    "\n",
    "positions = ['right_distal','right_proximal','left_distal','left_proximal','random']\n",
    "for position in positions:\n",
    "    print('electrode position:'+ position)\n",
    "    path=dataDir + '/'+position+'/' + 'data_test'\n",
    "    data=sio.loadmat(path)\n",
    "    X_test_raw = data['data_test']\n",
    "    path=dataDir + '/'+position+'/' + '/label_test'\n",
    "    data=sio.loadmat(path)\n",
    "    label_test = ((data['label_test']).T)\n",
    "    y_test_onehot = keras.utils.to_categorical(label_test.reshape(-1,), 6)\n",
    "    X_test = interpolation(X_test_raw,interpShape)\n",
    "\n",
    "    model_evaluate = []\n",
    "    model_evaluate.append(nnclf.evaluate(X_test,y_test_onehot))\n",
    "    print('model_evaluate',model_evaluate)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can run the following code to train your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnclf = NNclf((interpShape,interpShape,3))\n",
    "# nnclf.load_weights('./model/' + name + '_aug_autoencoder.h5',by_name = True)\n",
    "nnclf.summary()\n",
    "nnclf.compile(loss=categorical_crossentropy, optimizer=optimizers.Adam(lr=0.001), metrics=['acc'])\n",
    "nnclf.fit(x=X_train_with_aug, y=y_train_with_aug_onehot, batch_size=32, epochs=20, shuffle=True, validation_split=0.05)\n",
    "nnclf.compile(loss=categorical_crossentropy, optimizer=optimizers.Adam(lr=0.0001), metrics=['acc'])\n",
    "nnclf.fit(x=X_train_with_aug, y=y_train_with_aug_onehot, batch_size=32, epochs=20, shuffle=True, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnclf.save_weights('./model/nnclf.h5')\n",
    "print('electrode position: baseline')\n",
    "model_evaluate = []\n",
    "model_evaluate.append(nnclf.evaluate(X_test_baseline,y_test_onehot_baseline))\n",
    "print('model_evaluate',model_evaluate)\n",
    "\n",
    "positions = ['right_distal','right_proximal','left_distal','left_proximal','random']\n",
    "for position in positions:\n",
    "    print('electrode position:'+ position)\n",
    "    path=dataDir + '/'+position+'/' + 'data_test'\n",
    "    data=sio.loadmat(path)\n",
    "    X_test_raw = data['data_test']\n",
    "    path=dataDir + '/'+position+'/' + '/label_test'\n",
    "    data=sio.loadmat(path)\n",
    "    label_test = ((data['label_test']).T)\n",
    "    y_test_onehot = keras.utils.to_categorical(label_test.reshape(-1,), 6)\n",
    "    X_test = interpolation(X_test_raw,interpShape)\n",
    "\n",
    "    model_evaluate = []\n",
    "    model_evaluate.append(nnclf.evaluate(X_test,y_test_onehot))\n",
    "    print('model_evaluate',model_evaluate)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
